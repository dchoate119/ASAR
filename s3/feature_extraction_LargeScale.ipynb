{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45ed18-ecb8-453c-b1d0-723dbb1000ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing some feature extraction large scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa18036-f72a-48ea-926c-b08fd24c539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from math import radians, cos, sin\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ead676-f072-41f9-beef-65a22587003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ground images and satellite images\n",
    "\n",
    "# Images selected for local corrections\n",
    "image_1 = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/IMG_9475.JPEG\"\n",
    "image_2 = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/IMG_9464.JPEG\"\n",
    "image_3 = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/IMG_9467.JPEG\"\n",
    "image_4 = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/IMG_9473.JPEG\"\n",
    "image_5 = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/IMG_9476.JPEG\"\n",
    "# Load in satellite reference image\n",
    "sat_ref = \"/home/daniel-choate/Datasets/COLMAP/TTurfSAT/TTurf_Im/SAT.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df56506-ca5e-4c4b-b646-8eb4ee287c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_3)        # read the image from disk\n",
    "plt.imshow(image)\n",
    "# cv2.imshow(\"Image 1\", image)       # show it in a window named \"Image 1\"\n",
    "# cv2.waitKey(0)                     # wait for a key press\n",
    "# cv2.destroyAllWindows()            # close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cc2b6-9a19-4da4-8e04-981690e253d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, edge_blur=1.0, canny_low=50, canny_high=150):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5,5), edge_blur)\n",
    "    edges = cv2.Canny(blurred, canny_low, canny_high)\n",
    "    # Option: combine edges and gray: here we return both\n",
    "    return gray, edges\n",
    "\n",
    "def extract_sift(gray_or_edge, use_edges=False):\n",
    "    if use_edges:\n",
    "        inp = gray_or_edge\n",
    "    else:\n",
    "        inp = gray_or_edge\n",
    "    sift = cv2.SIFT_create()\n",
    "    kps, desc = sift.detectAndCompute(inp, None)\n",
    "    return kps, desc\n",
    "\n",
    "def root_sift(desc):\n",
    "    # desc: uint8->float, L1 normalize then sqrt\n",
    "    desc = desc.astype(np.float32)\n",
    "    desc /= (desc.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    return np.sqrt(desc)\n",
    "\n",
    "# FLANN matcher for SIFT\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "flann = cv2.FlannBasedMatcher(dict(algorithm=FLANN_INDEX_KDTREE, trees=5), {})\n",
    "\n",
    "def match_desc(d1, d2, ratio=0.7):\n",
    "    if d1 is None or d2 is None:\n",
    "        return []\n",
    "    matches = flann.knnMatch(d1, d2, k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    return good\n",
    "\n",
    "def rotate_image(img, angle_deg):\n",
    "    h,w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2,h/2), angle_deg, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w,h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def homography_ransac(kp1, kp2, matches, reprojThresh=3.0):\n",
    "    if len(matches) < 4:\n",
    "        return None, None\n",
    "    ptsA = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    ptsB = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "    H, status = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)\n",
    "    return H, status\n",
    "\n",
    "\n",
    "def match_with_rotation_search(ground_img, sat_img, use_edges=True,\n",
    "                               rot_range=45, rot_step=5, ratio=0.7):\n",
    "    # preprocess\n",
    "    g_gray, g_edges = preprocess(ground_img)\n",
    "    s_gray, s_edges = preprocess(sat_img)\n",
    "    g_input = g_edges if use_edges else g_gray\n",
    "    s_input = s_edges if use_edges else s_gray\n",
    "\n",
    "    # extract descriptors for satellite once\n",
    "    kp_s, desc_s = extract_sift(s_input)\n",
    "    if desc_s is not None:\n",
    "        desc_s = root_sift(desc_s)\n",
    "\n",
    "    best = {'inliers':0, 'H':None, 'angle':0, 'matches':None, 'kp_g':None, 'kp_s':kp_s}\n",
    "    # rotation search: rotate ground\n",
    "    angles = np.arange(-rot_range, rot_range+1, rot_step)\n",
    "    for ang in angles:\n",
    "        g_rot = rotate_image(g_input, ang)\n",
    "        kp_g, desc_g = extract_sift(g_rot)\n",
    "        if desc_g is None:\n",
    "            continue\n",
    "        desc_g = root_sift(desc_g)\n",
    "        good = match_desc(desc_g, desc_s, ratio=ratio)\n",
    "        if len(good) < 8:\n",
    "            continue\n",
    "        H, status = homography_ransac(kp_g, kp_s, good, reprojThresh=4.0)\n",
    "        if H is None:\n",
    "            continue\n",
    "        inliers = int(status.sum())\n",
    "        if inliers > best['inliers']:\n",
    "            best.update({'inliers': inliers, 'H': H, 'angle': ang, 'matches': good, 'kp_g':kp_g})\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ground_img = cv2.imread(image_3)\n",
    "sat_tile = cv2.imread(sat_ref)\n",
    "# print(sat_tile)\n",
    "\n",
    "\n",
    "# Example:\n",
    "result = match_with_rotation_search(ground_img, sat_tile, use_edges=True)\n",
    "print('Best angle', result['angle'], 'inliers', result['inliers'])\n",
    "if result['H'] is not None:\n",
    "    # warp ground into sat frame for visualization\n",
    "    g_warped = cv2.warpPerspective(rotate_image(preprocess(ground_img)[1], result['angle']), result['H'], (sat_tile.shape[1], sat_tile.shape[0]))\n",
    "    cv2.imwrite('warped.png', g_warped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3e62b-c9f7-48aa-97b4-0fa7cd132e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = cv2.drawMatches(rotate_image(preprocess(ground_img)[1], result['angle']),\n",
    "                      result['kp_g'],\n",
    "                      preprocess(sat_tile)[1],\n",
    "                      result['kp_s'],\n",
    "                      result['matches'], None,\n",
    "                      matchesMask=None, flags=2)\n",
    "cv2.imwrite('matches.png', vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038d455-22f7-4232-b354-5a059e0a0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- STEP 1: Load images ----------\n",
    "ground_img = cv2.imread(image_3)\n",
    "sat_img = cv2.imread(sat_ref)\n",
    "\n",
    "# Resize for easier visualization (optional)\n",
    "scale = 0.5\n",
    "ground_img = cv2.resize(ground_img, None, fx=scale, fy=scale)\n",
    "sat_img = cv2.resize(sat_img, None, fx=scale, fy=scale)\n",
    "\n",
    "# ---------- STEP 2: Select ground plane points ----------\n",
    "# Manual selection for the prototype\n",
    "print(\"Select 4 or more points on the GROUND image (press ENTER when done)\")\n",
    "g_points = []\n",
    "\n",
    "def click_event_ground(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        g_points.append([x, y])\n",
    "        cv2.circle(ground_img, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Ground Image\", ground_img)\n",
    "\n",
    "cv2.imshow(\"Ground Image\", ground_img)\n",
    "cv2.setMouseCallback(\"Ground Image\", click_event_ground)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "g_points = np.array(g_points, dtype=np.float32)\n",
    "print(f\"Selected ground points: {g_points}\")\n",
    "\n",
    "# ---------- STEP 3: Define ground-plane target coords ----------\n",
    "# Define where these points should appear in the bird's-eye frame.\n",
    "# For example, a 1000x1000 pixel rectangle for the ground plane\n",
    "width, height = 1000, 1000\n",
    "b_points = np.array([\n",
    "    [0, 0],\n",
    "    [width, 0],\n",
    "    [width, height],\n",
    "    [0, height]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Compute homography (ground image -> bird’s-eye)\n",
    "H_ground2bird, _ = cv2.findHomography(g_points, b_points)\n",
    "\n",
    "# Warp the image\n",
    "bird_eye = cv2.warpPerspective(ground_img, H_ground2bird, (width, height))\n",
    "\n",
    "cv2.imshow(\"Bird’s-eye View\", bird_eye)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ---------- STEP 4: Feature matching between bird-eye and satellite ----------\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_bird = cv2.cvtColor(bird_eye, cv2.COLOR_BGR2GRAY)\n",
    "gray_sat = cv2.cvtColor(sat_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT features\n",
    "sift = cv2.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(gray_bird, None)\n",
    "kp2, des2 = sift.detectAndCompute(gray_sat, None)\n",
    "\n",
    "# Match using FLANN + ratio test\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "# Draw initial matches\n",
    "draw_params = dict(matchColor=(0,255,0), singlePointColor=None, flags=2)\n",
    "img_matches = cv2.drawMatches(bird_eye, kp1, sat_img, kp2, good, None, **draw_params)\n",
    "cv2.imshow(\"Initial Matches\", img_matches)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ---------- STEP 5: Geometric verification ----------\n",
    "if len(good) > 4:\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    H_bs, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    matches_mask = mask.ravel().tolist()\n",
    "    inliers = np.sum(matches_mask)\n",
    "\n",
    "    print(f\"Found {inliers} inliers out of {len(good)} matches\")\n",
    "\n",
    "    img_inliers = cv2.drawMatches(bird_eye, kp1, sat_img, kp2, good, None,\n",
    "                                  matchColor=(0,255,0),\n",
    "                                  singlePointColor=None,\n",
    "                                  matchesMask=matches_mask, flags=2)\n",
    "    cv2.imshow(\"RANSAC Inliers\", img_inliers)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Not enough matches to compute homography.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e4798-019b-426c-8f95-cbe956aa2b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
