{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f00be8e-f7ee-4523-85c9-9c49e96db273",
   "metadata": {},
   "source": [
    "# Plotting COLMAP Data and Camera Poses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb2802-d999-47cd-987c-43ce556aff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo test scene: Gerrard Hall \n",
    "# Image data provided by COLMAP \n",
    "# Colmap generated: images, 3D points, cameras\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go \n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from colmapParsingUtils import *\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 180\n",
    "\n",
    "# Limit GPU memory, if running notebook on GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        memlim = 2*1024\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memlim)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54154f-b578-48d5-87f8-616b4013cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pose estimations from COLMAP \n",
    "\n",
    "images_colmap = read_images_text('/home/daniel-choate/ASAR/s2/COLMAP/GerrardHall/Project/images.txt')\n",
    "cameras = read_cameras_text('/home/daniel-choate/ASAR/s2/COLMAP/GerrardHall/Project/cameras.txt')\n",
    "pts3d = read_points3D_text('/home/daniel-choate/ASAR/s2/COLMAP/GerrardHall/Project/points3D.txt')\n",
    "\n",
    "# print(images[1])\n",
    "# print(cameras[1])\n",
    "# print(pts3d[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918a048-c09a-458a-8f2b-af59c0dc1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert COLMAP poses (xyz,quats) to rotm\n",
    "\n",
    "poses = np.zeros([len(images),4,4])\n",
    "images = np.zeros([len(poses),250,250,3])\n",
    "# ****????\n",
    "# images = np.zeros([len(poses),1000,1000,3]) #full resolution\n",
    "\n",
    "\n",
    "skip_indices = {56, 58}  # Use a set to store the indices to skip\n",
    "\n",
    "#loop through <images_from_colmap> to get 3D poses of cameras at each timestamp\n",
    "# print(len(images_from_colmap))\n",
    "for n in range(len(images_colmap)):\n",
    "    if n in skip_indices:\n",
    "        continue\n",
    "\n",
    "    trans31 = images_colmap[n+1].tvec[:,None]\n",
    "    # ****????\n",
    "\n",
    "    # from colmap2nerf import qvec2rotmat\n",
    "    # ****????\n",
    "\n",
    "    # Pull quaternion and translation vector\n",
    "    qvec = images_colmap[n+1].qvec #raw\n",
    "    tvec = images_colmap[n+1].tvec[:,None]\n",
    "    # print(tvec)\n",
    "    # ****????\n",
    "    \n",
    "    t = tvec.reshape([3,1])\n",
    "    # print(tvec)\n",
    "    R = qvec2rotmat(-qvec)\n",
    "    # ****????\n",
    "    \n",
    "    bottom = np.array([0.0, 0.0, 0.0, 1.0]).reshape([1, 4])\n",
    "    m = np.concatenate([np.concatenate([R, t], 1), bottom], 0)\n",
    "    c2w = np.linalg.inv(m)\n",
    "    \n",
    "    c2w[0:3,2] *= -1 # flip the y and z axis\n",
    "    c2w[0:3,1] *= -1\n",
    "    c2w = c2w[[1,0,2,3],:]\n",
    "    c2w[2,:] *= -1 # flip whole world upside down\n",
    "    # ****????\n",
    "\n",
    "\n",
    "    poses[n] = c2w\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    #line up z with origin\n",
    "    poses[n,2,-1] += 16 #desk\n",
    "    # poses[n,2,-1] += 10 #bike\n",
    "    # ****????\n",
    "\n",
    "    #downscale images\n",
    "    #sync order of images with order of poses\n",
    "    # temp = cv2.imread(\"desk_images/\"+images_colmap[n+1].name)/255    \n",
    "    # temp = cv2.resize(temp, dsize=(250,250), interpolation=cv2.INTER_CUBIC)\n",
    "#     temp = cv2.resize(temp, dsize=(100,100), interpolation=cv2.INTER_LINEAR)\n",
    "#     temp = cv2.resize(temp, dsize=(252,189), interpolation=cv2.INTER_LINEAR)#se f\n",
    "    # images[n,:,:,0] = temp[:,:,2]\n",
    "    # images[n,:,:,1] = temp[:,:,1]\n",
    "    # images[n,:,:,2] = temp[:,:,0]\n",
    "    # ****????\n",
    "\n",
    "#GET REST OF PARAMS NEEDED FOR tinyNeRF format~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n",
    "\n",
    "#fix order of colors\n",
    "images[:,:,:,0], images[:,:,:,1] = images[:,:,:,1], images[:,:,:,0]\n",
    "\n",
    "H,W = images.shape[1:3]\n",
    "# print(H,W)\n",
    "testimg, testpose = images[55], poses[55]\n",
    "\n",
    "focal = cameras[1].params[0] #test- see if same focal length can be shared across all images\n",
    "# focal = np.array(984.411).astype(np.double) #old\n",
    "# focal = np.array(98.4411).astype(np.double) # IMPORTANT --> LOOKS LIKE THIS NEEDS TO BE SCALED WHEN IMAGES ARE DOWNSAMPLED!\n",
    "# focal = int(focal/30)\n",
    "focal = focal/12\n",
    "print(focal)\n",
    "# print(poses)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90beeb-11c8-4495-ac8c-4cc3387cd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug coordinate system in <poses>\n",
    "\n",
    "# #scale poses to unit cube\n",
    "# radii = np.sqrt(np.sum(poses[:,:3,-1]**2, axis = 1))\n",
    "# print(max(radii))\n",
    "# poses[:,:3,-1] = 3*poses[:,:3,-1]/max(radii)\n",
    "\n",
    "\n",
    "# camera_centers = ax.scatter3D(poses[:,0,-1],poses[:,1,-1],poses[:,2,-1])\n",
    "headings = poses[:,:3,:3] @ np.array([0,0,-1]) #works\n",
    "\n",
    "# print(poses[0])\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.set_xlim([-6,6])\n",
    "ax.set_ylim([-6,6])\n",
    "ax.set_zlim([-6,6])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.grid(False)\n",
    "X, Y, Z = axes3d.get_test_data(0.05)\n",
    "# ax.contour(X, Y, Z, cmap=cm.coolwarm)  # Plot contour curves\n",
    "\n",
    "#plot axis\n",
    "ax.scatter3D(0,0,0, color='purple')\n",
    "ax.plot([0,1],[0,0],[0,0], color = 'red')\n",
    "ax.plot([0,0],[0,1],[0,0], color = 'green')\n",
    "ax.plot([0,0],[0,0],[0,1], color = 'blue')\n",
    "\n",
    "ax.quiver(poses[:,0,-1],poses[:,1,-1],poses[:,2,-1], headings[:,0], headings[:,1], headings[:,2], color = 'yellow', alpha = 0.5)\n",
    "headings = poses[:,:3,:3] @ np.array([1,0,0])\n",
    "ax.quiver(poses[:,0,-1],poses[:,1,-1],poses[:,2,-1], headings[:,0], headings[:,1], headings[:,2], color = 'red', alpha = 0.5)\n",
    "headings = poses[:,:3,:3] @ np.array([0,1,0])\n",
    "ax.quiver(poses[:,0,-1],poses[:,1,-1],poses[:,2,-1], headings[:,0], headings[:,1], headings[:,2], color = 'green', alpha = 0.5)\n",
    "headings = poses[:,:3,:3] @ np.array([0,0,1]) \n",
    "ax.quiver(poses[:,0,-1],poses[:,1,-1],poses[:,2,-1], headings[:,0], headings[:,1], headings[:,2], color = 'blue', alpha = 0.5)\n",
    "print(len(poses))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46faeb-9229-47d5-ac9b-da727f9e8f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10bbd96-84ae-4da4-a426-5037328b2d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61309068-60ec-4f8d-bdc1-ed420767a551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
